{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "src_folder = 'steps'\n",
        "cluster_name = 'cpu-cluster'\n",
        "env_name = \"data-drift-env\"\n",
        "\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to work with', ws.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to work with evolve-ml\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1649873237876
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a $src_folder/utils.py\n",
        "\n",
        "from contextlib import contextmanager\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def temp_directory(dir_name = 'temp', **kwds):\n",
        "    \n",
        "    os.makedirs(dir_name, exist_ok=True)\n",
        "    \n",
        "    try:\n",
        "        # print(client.server_info())\n",
        "\n",
        "        yield dir_name\n",
        "\n",
        "    except Exception:\n",
        "        print(f\"Unable to create '{dir_name}'\")\n",
        "\n",
        "    finally:\n",
        "        shutil.rmtree(dir_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing steps/utils.py\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $src_folder/collect-data-drift-output.py\n",
        "\n",
        "import argparse\n",
        "from azureml.core import Workspace, Dataset, Datastore, Run\n",
        "from azureml.core.run import _OfflineRun\n",
        "from azureml.data.dataset_factory import DataType\n",
        "\n",
        "DATASTORE_NAME = 'workspaceblobstore'\n",
        "FILE_DATASET_NAME = 'datadrift_file_results'\n",
        "json_file_path = f'datadrift/metrics/**/output_*.json'\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    #parser.add_argument('--output', dest='output', required=True)\n",
        "    #parser.add_argument('--datadir', dest='datadir', required=True)\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "args = parse_args()\n",
        "print(f'Arguments: {args.__dict__}')\n",
        "\n",
        "\n",
        "run = Run.get_context()\n",
        "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
        "\n",
        "# Crate FileDataSet based on datadrift metrics which are saved in datastore as json files\n",
        "dstore = Datastore.get(ws, DATASTORE_NAME)\n",
        "file_dataset = Dataset.File.from_files(path=(dstore,json_file_path))\n",
        "file_dataset.register(ws, FILE_DATASET_NAME, create_new_version=True)\n",
        "\n",
        "#TODO: \n",
        "## add filter dataset\n",
        "## add arguments instead of constants\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting steps/collect-data-drift-output.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $src_folder/transform-data-drift-output.py\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import bigjson\n",
        "import os\n",
        "import utils\n",
        "\n",
        "DATASTORE_PATH_PREFIX = 'datadrift_results'\n",
        "TEMP_DIRECTORY = 'temp'\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    #parser.add_argument('--output', dest='output', required=True)\n",
        "    #parser.add_argument('--datadir', dest='datadir', required=True)\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "args = parse_args()\n",
        "print(f'Arguments: {args.__dict__}')\n",
        "\n",
        "with temp_directory(TEMP_DIRECTORY):\n",
        "    # Download json files defined by the dataset to temp directory\n",
        "    json_file_paths = file_dataset.download(f'{TEMP_DIRECTORY}', overwrite=True)\n",
        "\n",
        "    # Convert json files to jsonl files (in local directory) \n",
        "    for json_path in json_file_paths:\n",
        "        \n",
        "        # Read json file in streaming mode\n",
        "        with open(json_path, 'rb') as f:\n",
        "            json_data = bigjson.load(f)\n",
        "            # Replace file name extension\n",
        "            jsonl_path = os.path.splitext(json_path)[0]+'.jsonl'\n",
        "\n",
        "            # Open jsonl file  \n",
        "            with open(jsonl_path, 'w') as jsonl_file:\n",
        "                # Iterates over input json\n",
        "                for data in json_data:\n",
        "                    # Converts json to a Python dict  \n",
        "                    dict_data = data.to_python()\n",
        "                    \n",
        "                    # Saves the data to jsonl file\n",
        "                    jsonl_file.write(json.dumps(dict_data)+\"\\n\")\n",
        "                    \n",
        "        # Delete json file\n",
        "        os.remove(json_path)\n",
        "\n",
        "    # Upload jsonl files to datastore\n",
        "    output_dataset = Dataset.File.upload_directory(f'{TEMP_DIRECTORY}', target=(dstore,DATASTORE_PATH_PREFIX))\n",
        "\n",
        "#TODO: \n",
        "## move to util\n",
        "## add arguments instead of constants\n",
        "## pass file_dataset from previous step\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing steps/transform-data-drift-output.py\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $src_folder/save-data-drift-output.py\n",
        "\n",
        "from azureml.core import Dataset, Datastore, Run\n",
        "from azureml.core.run import _OfflineRun\n",
        "from azureml.data.dataset_factory import DataType\n",
        "\n",
        "DATASTORE_NAME = 'workspaceblobstore'\n",
        "TABULAR_DATASET_NAME = 'datadrift_tabular_results'\n",
        "PARTITION_FORMAT = '{DATADRIFT_ID}/{PARTITION_DATE:yyyy/MM/dd}/output_{RUN_ID}.json'\n",
        "DATASTORE_PATH_PREFIX = 'datadrift_results'\n",
        "jsonl_file_path = DATASTORE_PATH_PREFIX + '/**/output_*.jsonl'\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    #parser.add_argument('--output', dest='output', required=True)\n",
        "    #parser.add_argument('--datadir', dest='datadir', required=True)\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "args = parse_args()\n",
        "print(f'Arguments: {args.__dict__}')\n",
        "\n",
        "\n",
        "run = Run.get_context()\n",
        "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
        "\n",
        "# Crate TabularDataSet based on converted jsonl files\n",
        "dstore = Datastore.get(ws, DATASTORE_NAME)\n",
        "output_dataset = Dataset.Tabular.from_json_lines_files(path=(dstore,jsonl_file_path), partition_format=PARTITION_FORMAT)\n",
        "output_dataset.register(ws, TABULAR_DATASET_NAME, create_new_version=True)\n",
        "\n",
        "#TODO: \n",
        "## add arguments instead of constants"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing steps/save-data-drift-output.py\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    from azureml.core.environment import Environment\n",
        "    from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "    myenv = Environment(name=env_name)\n",
        "    conda_dep = CondaDependencies()\n",
        "\n",
        "    conda_dep.add_pip_package('bigjson')\n",
        "    conda_dep.add_pip_package('azureml-defaults')\n",
        "\n",
        "    # Adds dependencies to PythonSection of myenv\n",
        "    myenv.python.conda_dependencies=conda_dep\n",
        "\n",
        "    myenv.register(ws).build(ws)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649873271621
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import RunConfiguration, ComputeTarget, Environment\n",
        "\n",
        "run_config = RunConfiguration()\n",
        "run_config.environment = Environment.get(ws, env_name)\n",
        "compute_target = ComputeTarget(ws, cluster_name)\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649873279141
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData, PipelineParameter\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "from azureml.core import ComputeTarget\n",
        "\n",
        "#datadir_param = PipelineData('datadir', is_directory=True)\n",
        "#evolve_param = PipelineData('evolve')\n",
        "#azure_param = PipelineData('azure')\n",
        "#compare_param = PipelineData('compare')\n",
        "\n",
        "#collection_param = PipelineParameter(name=\"collection\", default_value='test_datasets')\n",
        "#repo_param = PipelineParameter(name=\"repo\", default_value='test')\n",
        "\n",
        "collect_step = PythonScriptStep(\n",
        "    name='collect data drift output',\n",
        "    source_directory=src_folder,\n",
        "    script_name='collect-data-drift-output.py',\n",
        "    #arguments=['--output', 'azure.json', '--datadir', datadir_param],        \n",
        "    #outputs=[datadir_param, azure_param],\n",
        "    compute_target=compute_target, \n",
        "    runconfig=run_config,    \n",
        "    #allow_reuse=False, \n",
        ")\n",
        "\n",
        "transform_step = PythonScriptStep(\n",
        "    name='transform data drift output',\n",
        "    source_directory=src_folder,\n",
        "    script_name='transform-data-drift-output.py',\n",
        "    #arguments=['--output', 'evolve.json', '--datadir', datadir_param, '--collection', collection_param, '--repo', repo_param],    \n",
        "    #inputs=[datadir_param],\n",
        "    #outputs=[evolve_param],\n",
        "    compute_target=compute_target, \n",
        "    runconfig=run_config, \n",
        "    #allow_reuse=False,    \n",
        ")\n",
        "\n",
        "create_step = PythonScriptStep(\n",
        "    name='save data drift output',\n",
        "    source_directory=src_folder,\n",
        "    script_name='save-data-drift-output.py',\n",
        "    #arguments=['--target', 'evolve.json', '--source', 'azure.json', '--datadir', datadir_param, '--output', 'diff.json'],    \n",
        "    #inputs=[datadir_param, evolve_param, azure_param],\n",
        "    #outputs=[compare_param],\n",
        "    compute_target=compute_target, \n",
        "    runconfig=run_config,    \n",
        ")\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline steps defined\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649873457426
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Construct the pipeline\n",
        "pipeline_steps = [collect_step, transform_step, create_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace=ws, name = 'data-drift-output-exeriment')\n",
        "pipeline_run = experiment.submit(pipeline) \n",
        "print(\"Pipeline submitted for execution.\")\n",
        "\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step collect data drift output [0b5226e9][b55c86c3-d701-4a4d-a6bb-9aee83fd712b], (This step will run and generate new outputs)\nCreated step transform data drift output [b3ff03f1][1221cb61-c00a-4d4c-9906-636bd0805213], (This step will run and generate new outputs)\nCreated step save data [073e00cc][25bbcb96-2826-4e99-802c-7f88aa3dbb53], (This step will run and generate new outputs)\nSubmitted PipelineRun 4a6637c7-48f1-48f9-988a-25aa6bf508e2\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/4a6637c7-48f1-48f9-988a-25aa6bf508e2?wsid=/subscriptions/06c3d5bb-46a2-4d92-9508-c018d06f6452/resourcegroups/evolve-team-rg/workspaces/evolve-ml&tid=72a43063-967e-43c8-8121-0823266b2701\nPipeline submitted for execution.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "563261d914214ba2b51917340029f2b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/4a6637c7-48f1-48f9-988a-25aa6bf508e2?wsid=/subscriptions/06c3d5bb-46a2-4d92-9508-c018d06f6452/resourcegroups/evolve-team-rg/workspaces/evolve-ml&tid=72a43063-967e-43c8-8121-0823266b2701\", \"run_id\": \"4a6637c7-48f1-48f9-988a-25aa6bf508e2\", \"run_properties\": {\"run_id\": \"4a6637c7-48f1-48f9-988a-25aa6bf508e2\", \"created_utc\": \"2022-04-13T18:27:11.912634Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2022-04-13T18:30:51.532506Z\", \"status\": \"Failed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.4a6637c7-48f1-48f9-988a-25aa6bf508e2/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=KfhbH4ksRYy7ll2QwfHML3rzlXHAZ8L9226IFSBXRLc%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T18%3A28%3A09Z&se=2022-04-14T02%3A38%3A09Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.4a6637c7-48f1-48f9-988a-25aa6bf508e2/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=BtpLjQb9yNadoix8s6VofQs1k72An%2BONPAZsIlUWJj4%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T18%3A28%3A09Z&se=2022-04-14T02%3A38%3A09Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.4a6637c7-48f1-48f9-988a-25aa6bf508e2/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=xPwVFkHqVGeUyJMSm9YfGdttHKlWj5E7KxSKwQ40JDQ%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T18%3A28%3A09Z&se=2022-04-14T02%3A38%3A09Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:03:39\", \"run_number\": \"1649874432\", \"run_queued_details\": {\"status\": \"Failed\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"52d37611-0fc5-4273-8bfc-0336feb55758\", \"name\": \"collect data drift output\", \"status\": \"Canceled\", \"start_time\": \"2022-04-13T18:30:09.352677Z\", \"created_time\": \"2022-04-13T18:27:15.758293Z\", \"end_time\": \"2022-04-13T18:30:51.124322Z\", \"duration\": \"0:03:35\", \"run_number\": 1649874435, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T18:27:15.758293Z\", \"is_reused\": \"\"}, {\"run_id\": \"501c6d15-a209-45eb-a915-71a19c02b8bf\", \"name\": \"transform data drift output\", \"status\": \"Failed\", \"start_time\": \"2022-04-13T18:30:09.265674Z\", \"created_time\": \"2022-04-13T18:27:15.876488Z\", \"end_time\": \"2022-04-13T18:30:49.996028Z\", \"duration\": \"0:03:34\", \"run_number\": 1649874435, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T18:27:15.876488Z\", \"is_reused\": \"\"}, {\"run_id\": \"54a54840-40c0-4b81-b697-03687b6789c0\", \"name\": \"save data\", \"status\": \"Canceled\", \"start_time\": \"2022-04-13T18:30:09.516354Z\", \"created_time\": \"2022-04-13T18:27:15.916012Z\", \"end_time\": \"2022-04-13T18:30:50.936496Z\", \"duration\": \"0:03:35\", \"run_number\": 1649874435, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T18:27:15.916012Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-04-13 18:27:15Z] Submitting 3 runs, first five are: 073e00cc:54a54840-40c0-4b81-b697-03687b6789c0,0b5226e9:52d37611-0fc5-4273-8bfc-0336feb55758,b3ff03f1:501c6d15-a209-45eb-a915-71a19c02b8bf\\n[2022-04-13 18:30:51Z] Execution of experiment failed, update experiment status and cancel running nodes.\\n\", \"graph\": {\"datasource_nodes\": {}, \"module_nodes\": {\"0b5226e9\": {\"node_id\": \"0b5226e9\", \"name\": \"collect data drift output\", \"status\": \"Canceled\", \"_is_reused\": false, \"run_id\": \"52d37611-0fc5-4273-8bfc-0336feb55758\"}, \"b3ff03f1\": {\"node_id\": \"b3ff03f1\", \"name\": \"transform data drift output\", \"status\": \"Failed\", \"_is_reused\": false, \"run_id\": \"501c6d15-a209-45eb-a915-71a19c02b8bf\"}, \"073e00cc\": {\"node_id\": \"073e00cc\", \"name\": \"save data\", \"status\": \"Canceled\", \"_is_reused\": false, \"run_id\": \"54a54840-40c0-4b81-b697-03687b6789c0\"}}, \"edges\": [], \"child_runs\": [{\"run_id\": \"52d37611-0fc5-4273-8bfc-0336feb55758\", \"name\": \"collect data drift output\", \"status\": \"Canceled\", \"start_time\": \"2022-04-13T18:30:09.352677Z\", \"created_time\": \"2022-04-13T18:27:15.758293Z\", \"end_time\": \"2022-04-13T18:30:51.124322Z\", \"duration\": \"0:03:35\", \"run_number\": 1649874435, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T18:27:15.758293Z\", \"is_reused\": \"\"}, {\"run_id\": \"501c6d15-a209-45eb-a915-71a19c02b8bf\", \"name\": \"transform data drift output\", \"status\": \"Failed\", \"start_time\": \"2022-04-13T18:30:09.265674Z\", \"created_time\": \"2022-04-13T18:27:15.876488Z\", \"end_time\": \"2022-04-13T18:30:49.996028Z\", \"duration\": \"0:03:34\", \"run_number\": 1649874435, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T18:27:15.876488Z\", \"is_reused\": \"\"}, {\"run_id\": \"54a54840-40c0-4b81-b697-03687b6789c0\", \"name\": \"save data\", \"status\": \"Canceled\", \"start_time\": \"2022-04-13T18:30:09.516354Z\", \"created_time\": \"2022-04-13T18:27:15.916012Z\", \"end_time\": \"2022-04-13T18:30:50.936496Z\", \"duration\": \"0:03:35\", \"run_number\": 1649874435, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T18:27:15.916012Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.39.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: 4a6637c7-48f1-48f9-988a-25aa6bf508e2\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/4a6637c7-48f1-48f9-988a-25aa6bf508e2?wsid=/subscriptions/06c3d5bb-46a2-4d92-9508-c018d06f6452/resourcegroups/evolve-team-rg/workspaces/evolve-ml&tid=72a43063-967e-43c8-8121-0823266b2701\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: 52d37611-0fc5-4273-8bfc-0336feb55758\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/52d37611-0fc5-4273-8bfc-0336feb55758?wsid=/subscriptions/06c3d5bb-46a2-4d92-9508-c018d06f6452/resourcegroups/evolve-team-rg/workspaces/evolve-ml&tid=72a43063-967e-43c8-8121-0823266b2701\nStepRun( collect data drift output ) Status: Queued\nStepRun( collect data drift output ) Status: Running\n\nStepRun(collect data drift output) Execution Summary\n=====================================================\nStepRun( collect data drift output ) Status: Canceled\n\nWarnings:\n{\n  \"error\": {\n    \"code\": \"UserError\",\n    \"severity\": null,\n    \"message\": \"AzureMLCompute job failed.\\nExecutionFailed: [REDACTED]\\n\\texit_codes: 1\",\n    \"messageFormat\": \"{Message}\",\n    \"messageParameters\": {\n      \"Message\": \"AzureMLCompute job failed.\\nExecutionFailed: [REDACTED]\\n\\texit_codes: 1\"\n    },\n    \"referenceCode\": null,\n    \"detailsUri\": null,\n    \"target\": null,\n    \"details\": [],\n    \"innerError\": {\n      \"code\": \"UserTrainingScriptFailed\",\n      \"innerError\": null\n    },\n    \"debugInfo\": null,\n    \"additionalInfo\": null\n  },\n  \"correlation\": {\n    \"operation\": \"919ad490fdbcd765ffc3216c314ac566\",\n    \"request\": \"c92ddd30165ecdfd\"\n  },\n  \"environment\": \"westeurope\",\n  \"location\": \"westeurope\",\n  \"time\": \"2022-04-13T18:30:51.0239844+00:00\",\n  \"componentName\": \"globaljobdispatcher\"\n}\n"
        },
        {
          "output_type": "error",
          "ename": "ActivityFailedException",
          "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"{'code': ExecutionFailed, 'message': [{\\\"exit_code\\\":1,\\\"error_message\\\":\\\"Execution failed with error: Arguments: {}\\\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\\\n0 items cleaning up...\\\\nCleanup took 7.152557373046875e-07 seconds\\\\n[stderr]Traceback (most recent call last):\\\\n[stderr]  File \\\\\\\"collect-data-drift-output.py\\\\\\\", line 23, in <module>\\\\n[stderr]    ws = Workspace.from_config()\\\\n[stderr]  File \\\\\\\"/azureml-envs/azureml_d9438b93de534f7f3a68847348170eaf/lib/python3.6/site-packages/azureml/core/workspace.py\\\\\\\", line 285, in from_config\\\\n[stderr]    normalized_path))\\\\n[stderr]azureml.exceptions._azureml_exception.UserErrorException: UserErrorException:\\\\n[stderr]\\\\tMessage: The workspace configuration file config.json, could not be found in /mnt/azureml/cr/j/0ac1266120944263919b2558a2b06343/exe/wd or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http://ml.azure.com and clicking on the name of your workspace in the right top.\\\\n[stderr]\\\\tInnerException None\\\\n[stderr]\\\\tErrorResponse \\\\n[stderr]{\\\\n[stderr]    \\\\\\\"error\\\\\\\": {\\\\n[stderr]        \\\\\\\"code\\\\\\\": \\\\\\\"UserError\\\\\\\",\\\\n[stderr]        \\\\\\\"message\\\\\\\": \\\\\\\"The workspace configuration file config.json, could not be found in /mnt/azureml/cr/j/0ac1266120944263919b2558a2b06343/exe/wd or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http://ml.azure.com and clicking on the name of your workspace in the right top.\\\\\\\"\\\\n[stderr]    }\\\\n[stderr]}\\\\n[stderr]\\\\n\\\",\\\"process_name\\\":\\\"/azureml-envs/azureml_d9438b93de534f7f3a68847348170eaf/bin/python\\\",\\\"error_file\\\":\\\"user_logs/std_log.txt\\\"}], 'target': , 'category': UserError, 'error_details': [{'key': exit_codes, 'value': 1}, ], 'inner_error': null}\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"{'code': ExecutionFailed, 'message': [{\\\\\\\"exit_code\\\\\\\":1,\\\\\\\"error_message\\\\\\\":\\\\\\\"Execution failed with error: Arguments: {}\\\\\\\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\\\\\\\n0 items cleaning up...\\\\\\\\nCleanup took 7.152557373046875e-07 seconds\\\\\\\\n[stderr]Traceback (most recent call last):\\\\\\\\n[stderr]  File \\\\\\\\\\\\\\\"collect-data-drift-output.py\\\\\\\\\\\\\\\", line 23, in <module>\\\\\\\\n[stderr]    ws = Workspace.from_config()\\\\\\\\n[stderr]  File \\\\\\\\\\\\\\\"/azureml-envs/azureml_d9438b93de534f7f3a68847348170eaf/lib/python3.6/site-packages/azureml/core/workspace.py\\\\\\\\\\\\\\\", line 285, in from_config\\\\\\\\n[stderr]    normalized_path))\\\\\\\\n[stderr]azureml.exceptions._azureml_exception.UserErrorException: UserErrorException:\\\\\\\\n[stderr]\\\\\\\\tMessage: The workspace configuration file config.json, could not be found in /mnt/azureml/cr/j/0ac1266120944263919b2558a2b06343/exe/wd or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http://ml.azure.com and clicking on the name of your workspace in the right top.\\\\\\\\n[stderr]\\\\\\\\tInnerException None\\\\\\\\n[stderr]\\\\\\\\tErrorResponse \\\\\\\\n[stderr]{\\\\\\\\n[stderr]    \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\": {\\\\\\\\n[stderr]        \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"UserError\\\\\\\\\\\\\\\",\\\\\\\\n[stderr]        \\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"The workspace configuration file config.json, could not be found in /mnt/azureml/cr/j/0ac1266120944263919b2558a2b06343/exe/wd or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http://ml.azure.com and clicking on the name of your workspace in the right top.\\\\\\\\\\\\\\\"\\\\\\\\n[stderr]    }\\\\\\\\n[stderr]}\\\\\\\\n[stderr]\\\\\\\\n\\\\\\\",\\\\\\\"process_name\\\\\\\":\\\\\\\"/azureml-envs/azureml_d9438b93de534f7f3a68847348170eaf/bin/python\\\\\\\",\\\\\\\"error_file\\\\\\\":\\\\\\\"user_logs/std_log.txt\\\\\\\"}], 'target': , 'category': UserError, 'error_details': [{'key': exit_codes, 'value': 1}, ], 'inner_error': null}\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-fa769d2e97b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0m\u001b[1;32m    296\u001b[0m                                                              raise_on_error=raise_on_error)\n\u001b[1;32m    297\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0m\u001b[1;32m    738\u001b[0m                                                raise_on_error=raise_on_error)\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"{'code': ExecutionFailed, 'message': [{\\\"exit_code\\\":1,\\\"error_message\\\":\\\"Execution failed with error: Arguments: {}\\\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\\\n0 items cleaning up...\\\\nCleanup took 7.152557373046875e-07 seconds\\\\n[stderr]Traceback (most recent call last):\\\\n[stderr]  File \\\\\\\"collect-data-drift-output.py\\\\\\\", line 23, in <module>\\\\n[stderr]    ws = Workspace.from_config()\\\\n[stderr]  File \\\\\\\"/azureml-envs/azureml_d9438b93de534f7f3a68847348170eaf/lib/python3.6/site-packages/azureml/core/workspace.py\\\\\\\", line 285, in from_config\\\\n[stderr]    normalized_path))\\\\n[stderr]azureml.exceptions._azureml_exception.UserErrorException: UserErrorException:\\\\n[stderr]\\\\tMessage: The workspace configuration file config.json, could not be found in /mnt/azureml/cr/j/0ac1266120944263919b2558a2b06343/exe/wd or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http://ml.azure.com and clicking on the name of your workspace in the right top.\\\\n[stderr]\\\\tInnerException None\\\\n[stderr]\\\\tErrorResponse \\\\n[stderr]{\\\\n[stderr]    \\\\\\\"error\\\\\\\": {\\\\n[stderr]        \\\\\\\"code\\\\\\\": \\\\\\\"UserError\\\\\\\",\\\\n[stderr]        \\\\\\\"message\\\\\\\": \\\\\\\"The workspace configuration file config.json, could not be found in /mnt/azureml/cr/j/0ac1266120944263919b2558a2b06343/exe/wd or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http://ml.azure.com and clicking on the name of your workspace in the right top.\\\\\\\"\\\\n[stderr]    }\\\\n[stderr]}\\\\n[stderr]\\\\n\\\",\\\"process_name\\\":\\\"/azureml-envs/azureml_d9438b93de534f7f3a68847348170eaf/bin/python\\\",\\\"error_file\\\":\\\"user_logs/std_log.txt\\\"}], 'target': , 'category': UserError, 'error_details': [{'key': exit_codes, 'value': 1}, ], 'inner_error': null}\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"{'code': ExecutionFailed, 'message': [{\\\\\\\"exit_code\\\\\\\":1,\\\\\\\"error_message\\\\\\\":\\\\\\\"Execution failed with error: Arguments: {}\\\\\\\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\\\\\\\n0 items cleaning up...\\\\\\\\nCleanup took 7.152557373046875e-07 seconds\\\\\\\\n[stderr]Traceback (most recent call last):\\\\\\\\n[stderr]  File \\\\\\\\\\\\\\\"collect-data-drift-output.py\\\\\\\\\\\\\\\", line 23, in <module>\\\\\\\\n[stderr]    ws = Workspace.from_config()\\\\\\\\n[stderr]  File \\\\\\\\\\\\\\\"/azureml-envs/azureml_d9438b93de534f7f3a68847348170eaf/lib/python3.6/site-packages/azureml/core/workspace.py\\\\\\\\\\\\\\\", line 285, in from_config\\\\\\\\n[stderr]    normalized_path))\\\\\\\\n[stderr]azureml.exceptions._azureml_exception.UserErrorException: UserErrorException:\\\\\\\\n[stderr]\\\\\\\\tMessage: The workspace configuration file config.json, could not be found in /mnt/azureml/cr/j/0ac1266120944263919b2558a2b06343/exe/wd or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http://ml.azure.com and clicking on the name of your workspace in the right top.\\\\\\\\n[stderr]\\\\\\\\tInnerException None\\\\\\\\n[stderr]\\\\\\\\tErrorResponse \\\\\\\\n[stderr]{\\\\\\\\n[stderr]    \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\": {\\\\\\\\n[stderr]        \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"UserError\\\\\\\\\\\\\\\",\\\\\\\\n[stderr]        \\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"The workspace configuration file config.json, could not be found in /mnt/azureml/cr/j/0ac1266120944263919b2558a2b06343/exe/wd or its parent directories. Please check whether the workspace configuration file exists, or provide the full path to the configuration file as an argument. You can download a configuration file for your workspace, via http://ml.azure.com and clicking on the name of your workspace in the right top.\\\\\\\\\\\\\\\"\\\\\\\\n[stderr]    }\\\\\\\\n[stderr]}\\\\\\\\n[stderr]\\\\\\\\n\\\\\\\",\\\\\\\"process_name\\\\\\\":\\\\\\\"/azureml-envs/azureml_d9438b93de534f7f3a68847348170eaf/bin/python\\\\\\\",\\\\\\\"error_file\\\\\\\":\\\\\\\"user_logs/std_log.txt\\\\\\\"}], 'target': , 'category': UserError, 'error_details': [{'key': exit_codes, 'value': 1}, ], 'inner_error': null}\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649874659158
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineRun\n",
        "from azureml.core import Experiment\n",
        "\n",
        "# Publish the pipeline from the run\n",
        "submitted_pipeline_run = PipelineRun(experiment=Experiment(experiment, run_id=pipeline_run.id))\n",
        "published_pipeline = submitted_pipeline_run.publish_pipeline(name='data-drift-output-pipeline',\n",
        "    description='collect, transform and save datadrift output into dataset',\n",
        "    version='1.0',\n",
        "    continue_on_step_failure=False)\n",
        "\n",
        "print('Pipeline scheduled.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
        "\n",
        "# Schedules a daily run of a published pipeline\n",
        "daily = ScheduleRecurrence(frequency='Day', interval=1)\n",
        "pipeline_schedule = Schedule.create(ws, name='data_drift_output_schedule',\n",
        "                                        description='update data drift output every day',\n",
        "                                        pipeline_id=published_pipeline.id,\n",
        "                                        experiment_name='schedule_data_drift_output_pipeline',\n",
        "                                        recurrence=daily)\n",
        "\n",
        "print('Pipeline scheduled.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}