{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "src_folder = 'steps'\n",
        "cluster_name = 'cpu-cluster'\n",
        "env_name = \"data-drift-env\"\n",
        "\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to work with', ws.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to work with evolve-ml\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1649876646107
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a $src_folder/utils.py\n",
        "\n",
        "from contextlib import contextmanager\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def temp_directory(dir_name = 'temp', **kwds):\n",
        "    \n",
        "    os.makedirs(dir_name, exist_ok=True)\n",
        "    \n",
        "    try:\n",
        "        # print(client.server_info())\n",
        "\n",
        "        yield dir_name\n",
        "\n",
        "    except Exception:\n",
        "        print(f\"Unable to create '{dir_name}'\")\n",
        "\n",
        "    finally:\n",
        "        shutil.rmtree(dir_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Appending to steps/utils.py\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $src_folder/collect-data-drift-output.py\n",
        "\n",
        "import argparse\n",
        "from azureml.core import Workspace, Dataset, Datastore, Run\n",
        "from azureml.core.run import _OfflineRun\n",
        "from azureml.data.dataset_factory import DataType\n",
        "\n",
        "DATASTORE_NAME = 'workspaceblobstore'\n",
        "FILE_DATASET_NAME = 'datadrift_file_results'\n",
        "json_file_path = f'datadrift/metrics/**/output_*.json'\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    #parser.add_argument('--output', dest='output', required=True)\n",
        "    #parser.add_argument('--datadir', dest='datadir', required=True)\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "args = parse_args()\n",
        "print(f'Arguments: {args.__dict__}')\n",
        "\n",
        "\n",
        "run = Run.get_context()\n",
        "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
        "\n",
        "# Crate FileDataSet based on datadrift metrics which are saved in datastore as json files\n",
        "dstore = Datastore.get(ws, DATASTORE_NAME)\n",
        "file_dataset = Dataset.File.from_files(path=(dstore,json_file_path))\n",
        "file_dataset.register(ws, FILE_DATASET_NAME, create_new_version=True)\n",
        "\n",
        "#TODO: \n",
        "## add filter dataset\n",
        "## add arguments instead of constants\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting steps/collect-data-drift-output.py\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $src_folder/transform-data-drift-output.py\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import bigjson\n",
        "import os\n",
        "import utils\n",
        "from azureml.core import Workspace, Dataset, Datastore, Run\n",
        "from azureml.core.run import _OfflineRun\n",
        "\n",
        "DATASTORE_NAME = 'workspaceblobstore'\n",
        "DATASTORE_PATH_PREFIX = 'datadrift_results'\n",
        "TEMP_DIRECTORY = 'temp'\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    #parser.add_argument('--output', dest='output', required=True)\n",
        "    #parser.add_argument('--datadir', dest='datadir', required=True)\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "args = parse_args()\n",
        "print(f'Arguments: {args.__dict__}')\n",
        "\n",
        "run = Run.get_context()\n",
        "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
        "dstore = Datastore.get(ws, DATASTORE_NAME)\n",
        "\n",
        "with utils.temp_directory(TEMP_DIRECTORY):\n",
        "    # Download json files defined by the dataset to temp directory\n",
        "    json_file_paths = file_dataset.download(f'{TEMP_DIRECTORY}', overwrite=True)\n",
        "\n",
        "    # Convert json files to jsonl files (in local directory) \n",
        "    for json_path in json_file_paths:\n",
        "        \n",
        "        # Read json file in streaming mode\n",
        "        with open(json_path, 'rb') as f:\n",
        "            json_data = bigjson.load(f)\n",
        "            # Replace file name extension\n",
        "            jsonl_path = os.path.splitext(json_path)[0]+'.jsonl'\n",
        "\n",
        "            # Open jsonl file  \n",
        "            with open(jsonl_path, 'w') as jsonl_file:\n",
        "                # Iterates over input json\n",
        "                for data in json_data:\n",
        "                    # Converts json to a Python dict  \n",
        "                    dict_data = data.to_python()\n",
        "                    \n",
        "                    # Saves the data to jsonl file\n",
        "                    jsonl_file.write(json.dumps(dict_data)+\"\\n\")\n",
        "                    \n",
        "        # Delete json file\n",
        "        os.remove(json_path)\n",
        "\n",
        "    # Upload jsonl files to datastore\n",
        "    output_dataset = Dataset.File.upload_directory(f'{TEMP_DIRECTORY}', target=(dstore,DATASTORE_PATH_PREFIX))\n",
        "\n",
        "#TODO: \n",
        "## move to util\n",
        "## add arguments instead of constants\n",
        "## pass file_dataset from previous step\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting steps/transform-data-drift-output.py\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $src_folder/save-data-drift-output.py\n",
        "\n",
        "import argparse\n",
        "from azureml.core import Dataset, Datastore, Run\n",
        "from azureml.core.run import _OfflineRun\n",
        "from azureml.data.dataset_factory import DataType\n",
        "\n",
        "DATASTORE_NAME = 'workspaceblobstore'\n",
        "TABULAR_DATASET_NAME = 'datadrift_tabular_results'\n",
        "PARTITION_FORMAT = '{DATADRIFT_ID}/{PARTITION_DATE:yyyy/MM/dd}/output_{RUN_ID}.json'\n",
        "DATASTORE_PATH_PREFIX = 'datadrift_results'\n",
        "jsonl_file_path = DATASTORE_PATH_PREFIX + '/**/output_*.jsonl'\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    #parser.add_argument('--output', dest='output', required=True)\n",
        "    #parser.add_argument('--datadir', dest='datadir', required=True)\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "args = parse_args()\n",
        "print(f'Arguments: {args.__dict__}')\n",
        "\n",
        "\n",
        "run = Run.get_context()\n",
        "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
        "\n",
        "# Crate TabularDataSet based on converted jsonl files\n",
        "dstore = Datastore.get(ws, DATASTORE_NAME)\n",
        "output_dataset = Dataset.Tabular.from_json_lines_files(path=(dstore,jsonl_file_path), partition_format=PARTITION_FORMAT)\n",
        "output_dataset.register(ws, TABULAR_DATASET_NAME, create_new_version=True)\n",
        "\n",
        "#TODO: \n",
        "## add arguments instead of constants"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting steps/save-data-drift-output.py\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    from azureml.core.environment import Environment\n",
        "    from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "    myenv = Environment(name=env_name)\n",
        "    conda_dep = CondaDependencies()\n",
        "\n",
        "    conda_dep.add_pip_package('bigjson')\n",
        "    conda_dep.add_pip_package('azureml-defaults')\n",
        "\n",
        "    # Adds dependencies to PythonSection of myenv\n",
        "    myenv.python.conda_dependencies=conda_dep\n",
        "\n",
        "    myenv.register(ws).build(ws)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649873271621
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import RunConfiguration, ComputeTarget, Environment\n",
        "\n",
        "run_config = RunConfiguration()\n",
        "run_config.environment = Environment.get(ws, env_name)\n",
        "compute_target = ComputeTarget(ws, cluster_name)\n"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649876668607
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData, PipelineParameter\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "from azureml.core import ComputeTarget\n",
        "\n",
        "#datadir_param = PipelineData('datadir', is_directory=True)\n",
        "#evolve_param = PipelineData('evolve')\n",
        "#azure_param = PipelineData('azure')\n",
        "#compare_param = PipelineData('compare')\n",
        "\n",
        "#collection_param = PipelineParameter(name=\"collection\", default_value='test_datasets')\n",
        "#repo_param = PipelineParameter(name=\"repo\", default_value='test')\n",
        "\n",
        "collect_step = PythonScriptStep(\n",
        "    name='collect data drift output',\n",
        "    source_directory=src_folder,\n",
        "    script_name='collect-data-drift-output.py',\n",
        "    #arguments=['--output', 'azure.json', '--datadir', datadir_param],        \n",
        "    #outputs=[datadir_param, azure_param],\n",
        "    compute_target=compute_target, \n",
        "    runconfig=run_config, \n",
        "    allow_reuse=False,   \n",
        ")\n",
        "\n",
        "transform_step = PythonScriptStep(\n",
        "    name='transform data drift output',\n",
        "    source_directory=src_folder,\n",
        "    script_name='transform-data-drift-output.py',\n",
        "    #arguments=['--output', 'evolve.json', '--datadir', datadir_param, '--collection', collection_param, '--repo', repo_param],    \n",
        "    #inputs=[datadir_param],\n",
        "    #outputs=[evolve_param],\n",
        "    compute_target=compute_target, \n",
        "    runconfig=run_config, \n",
        "    allow_reuse=False,    \n",
        ")\n",
        "\n",
        "save_step = PythonScriptStep(\n",
        "    name='save data drift output',\n",
        "    source_directory=src_folder,\n",
        "    script_name='save-data-drift-output.py',\n",
        "    #arguments=['--target', 'evolve.json', '--source', 'azure.json', '--datadir', datadir_param, '--output', 'diff.json'],    \n",
        "    #inputs=[datadir_param, evolve_param, azure_param],\n",
        "    #outputs=[compare_param],\n",
        "    compute_target=compute_target, \n",
        "    runconfig=run_config,    \n",
        "    allow_reuse=False,\n",
        ")\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline steps defined\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649880724723
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Construct the pipeline\n",
        "pipeline_steps = [collect_step, transform_step, save_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace=ws, name = 'data-drift-output-exeriment')\n",
        "pipeline_run = experiment.submit(pipeline) \n",
        "print(\"Pipeline submitted for execution.\")\n",
        "\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step collect data drift output [b7e380ae][82efed4b-f05c-4261-a3cb-d81e385e4525], (This step will run and generate new outputs)Created step transform data drift output [7ab0f089][2e347405-0cb1-4e7e-b4f1-d4d7ecc466ba], (This step will run and generate new outputs)\n\nCreated step save data drift output [dc169218][a39e30c6-23ae-450f-be09-79425a09c71d], (This step will run and generate new outputs)\nSubmitted PipelineRun 4ed29cd0-bc79-4295-873c-2cb4d3bde788\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/4ed29cd0-bc79-4295-873c-2cb4d3bde788?wsid=/subscriptions/06c3d5bb-46a2-4d92-9508-c018d06f6452/resourcegroups/evolve-team-rg/workspaces/evolve-ml&tid=72a43063-967e-43c8-8121-0823266b2701\nPipeline submitted for execution.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82e202446d25496ea5f294fdfd7bba7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/4ed29cd0-bc79-4295-873c-2cb4d3bde788?wsid=/subscriptions/06c3d5bb-46a2-4d92-9508-c018d06f6452/resourcegroups/evolve-team-rg/workspaces/evolve-ml&tid=72a43063-967e-43c8-8121-0823266b2701\", \"run_id\": \"4ed29cd0-bc79-4295-873c-2cb4d3bde788\", \"run_properties\": {\"run_id\": \"4ed29cd0-bc79-4295-873c-2cb4d3bde788\", \"created_utc\": \"2022-04-13T20:12:45.243309Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2022-04-13T20:17:10.887314Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.4ed29cd0-bc79-4295-873c-2cb4d3bde788/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=buS3pXeRlvXU7vGLLzRE1L%2Bmvz2mSiRwIT0b1dfNbLQ%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A08%3A13Z&se=2022-04-14T04%3A18%3A13Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.4ed29cd0-bc79-4295-873c-2cb4d3bde788/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=NoegnzjfYJ9X18ZZP%2FybzA5Li%2BhDQoO4djBaAV5SRMs%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A08%3A13Z&se=2022-04-14T04%3A18%3A13Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.4ed29cd0-bc79-4295-873c-2cb4d3bde788/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=eqGYZ%2FqZBD5MVsaKgrKszKNpuC7A8E%2FupfyHbZH9u3g%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A08%3A13Z&se=2022-04-14T04%3A18%3A13Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:04:25\", \"run_number\": \"1649880765\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"15878bbc-297e-4180-8350-dd780e0a8cba\", \"name\": \"collect data drift output\", \"status\": \"Finished\", \"start_time\": \"2022-04-13T20:16:27.840186Z\", \"created_time\": \"2022-04-13T20:12:47.60336Z\", \"end_time\": \"2022-04-13T20:17:08.867767Z\", \"duration\": \"0:04:21\", \"run_number\": 1649880767, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T20:12:47.60336Z\", \"is_reused\": \"\"}, {\"run_id\": \"50a7eaa6-9e85-4cce-b5ab-af1fdae9b783\", \"name\": \"transform data drift output\", \"status\": \"Finished\", \"start_time\": \"2022-04-13T20:16:29.031363Z\", \"created_time\": \"2022-04-13T20:12:47.585565Z\", \"end_time\": \"2022-04-13T20:17:07.309745Z\", \"duration\": \"0:04:19\", \"run_number\": 1649880767, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T20:12:47.585565Z\", \"is_reused\": \"\"}, {\"run_id\": \"df55eae4-d8b8-4943-8ee4-9718a7444070\", \"name\": \"save data drift output\", \"status\": \"Finished\", \"start_time\": \"2022-04-13T20:16:27.653719Z\", \"created_time\": \"2022-04-13T20:12:47.586292Z\", \"end_time\": \"2022-04-13T20:17:09.483417Z\", \"duration\": \"0:04:21\", \"run_number\": 1649880767, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T20:12:47.586292Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-04-13 20:12:47Z] Submitting 3 runs, first five are: 7ab0f089:50a7eaa6-9e85-4cce-b5ab-af1fdae9b783,b7e380ae:15878bbc-297e-4180-8350-dd780e0a8cba,dc169218:df55eae4-d8b8-4943-8ee4-9718a7444070\\n[2022-04-13 20:17:09Z] Completing processing run id 50a7eaa6-9e85-4cce-b5ab-af1fdae9b783.\\n[2022-04-13 20:17:09Z] Completing processing run id 15878bbc-297e-4180-8350-dd780e0a8cba.\\n[2022-04-13 20:17:10Z] Completing processing run id df55eae4-d8b8-4943-8ee4-9718a7444070.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {}, \"module_nodes\": {\"b7e380ae\": {\"node_id\": \"b7e380ae\", \"name\": \"collect data drift output\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"15878bbc-297e-4180-8350-dd780e0a8cba\"}, \"7ab0f089\": {\"node_id\": \"7ab0f089\", \"name\": \"transform data drift output\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"50a7eaa6-9e85-4cce-b5ab-af1fdae9b783\"}, \"dc169218\": {\"node_id\": \"dc169218\", \"name\": \"save data drift output\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"df55eae4-d8b8-4943-8ee4-9718a7444070\"}}, \"edges\": [], \"child_runs\": [{\"run_id\": \"15878bbc-297e-4180-8350-dd780e0a8cba\", \"name\": \"collect data drift output\", \"status\": \"Finished\", \"start_time\": \"2022-04-13T20:16:27.840186Z\", \"created_time\": \"2022-04-13T20:12:47.60336Z\", \"end_time\": \"2022-04-13T20:17:08.867767Z\", \"duration\": \"0:04:21\", \"run_number\": 1649880767, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T20:12:47.60336Z\", \"is_reused\": \"\"}, {\"run_id\": \"50a7eaa6-9e85-4cce-b5ab-af1fdae9b783\", \"name\": \"transform data drift output\", \"status\": \"Finished\", \"start_time\": \"2022-04-13T20:16:29.031363Z\", \"created_time\": \"2022-04-13T20:12:47.585565Z\", \"end_time\": \"2022-04-13T20:17:07.309745Z\", \"duration\": \"0:04:19\", \"run_number\": 1649880767, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T20:12:47.585565Z\", \"is_reused\": \"\"}, {\"run_id\": \"df55eae4-d8b8-4943-8ee4-9718a7444070\", \"name\": \"save data drift output\", \"status\": \"Finished\", \"start_time\": \"2022-04-13T20:16:27.653719Z\", \"created_time\": \"2022-04-13T20:12:47.586292Z\", \"end_time\": \"2022-04-13T20:17:09.483417Z\", \"duration\": \"0:04:21\", \"run_number\": 1649880767, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-04-13T20:12:47.586292Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.39.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: 4ed29cd0-bc79-4295-873c-2cb4d3bde788\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/4ed29cd0-bc79-4295-873c-2cb4d3bde788?wsid=/subscriptions/06c3d5bb-46a2-4d92-9508-c018d06f6452/resourcegroups/evolve-team-rg/workspaces/evolve-ml&tid=72a43063-967e-43c8-8121-0823266b2701\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: df55eae4-d8b8-4943-8ee4-9718a7444070\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/df55eae4-d8b8-4943-8ee4-9718a7444070?wsid=/subscriptions/06c3d5bb-46a2-4d92-9508-c018d06f6452/resourcegroups/evolve-team-rg/workspaces/evolve-ml&tid=72a43063-967e-43c8-8121-0823266b2701\nStepRun( save data drift output ) Status: Running\n\nStepRun(save data drift output) Execution Summary\n==================================================\nStepRun( save data drift output ) Status: Finished\n{'runId': 'df55eae4-d8b8-4943-8ee4-9718a7444070', 'target': 'cpu-cluster', 'status': 'Completed', 'startTimeUtc': '2022-04-13T20:16:27.653719Z', 'endTimeUtc': '2022-04-13T20:17:09.483417Z', 'services': {}, 'properties': {'ContentSnapshotId': 'ebd02ff7-dc35-43d8-8a7f-1d3d31b4d328', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'a39e30c6-23ae-450f-be09-79425a09c71d', 'azureml.moduleName': 'save data drift output', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'dc169218', 'azureml.pipelinerunid': '4ed29cd0-bc79-4295-873c-2cb4d3bde788', 'azureml.pipeline': '4ed29cd0-bc79-4295-873c-2cb4d3bde788', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [{'identifier': {'savedId': 'afb6af15-3c43-4961-90f1-d7b10d2fb0f9', 'registeredId': '52e94d86-a162-475c-8c0c-8116671d068c', 'registeredVersion': '3'}, 'outputType': 'Reference', 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'datadrift_results/**/output_*.jsonl')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\",\n    \"ParseJsonLines\",\n    \"AddColumnsFromPartitionFormat\",\n    \"DropColumns\"\n  ],\n  \"registration\": {\n    \"id\": \"afb6af15-3c43-4961-90f1-d7b10d2fb0f9\",\n    \"name\": \"datadrift_tabular_results\",\n    \"version\": 3,\n    \"workspace\": \"Workspace.create(name='evolve-ml', subscription_id='06c3d5bb-46a2-4d92-9508-c018d06f6452', resource_group='evolve-team-rg')\"\n  }\n}}], 'runDefinition': {'script': 'save-data-drift-output.py', 'command': '', 'useAbsolutePath': False, 'arguments': [], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpu-cluster', 'dataReferences': {}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'data-drift-env', 'version': '1', 'assetId': 'azureml://locations/westeurope/workspaces/899eb723-9471-475e-9ea2-abcad8a41de5/environments/data-drift-env/versions/1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['bigjson', 'azureml-defaults']}], 'name': 'azureml_d9438b93de534f7f3a68847348170eaf'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/backgroundProcess.log': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.df55eae4-d8b8-4943-8ee4-9718a7444070/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=btG30hNQmRwygQmLSZL%2F7VJ%2FxFpZ2xgSsk3a6U9Sc68%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A07%3A06Z&se=2022-04-14T04%3A17%3A06Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.df55eae4-d8b8-4943-8ee4-9718a7444070/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=i7jQBvO%2FOwiPQWQGcuI1DIjBpSNjIEicClnPR1lKoGY%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A07%3A06Z&se=2022-04-14T04%3A17%3A06Z&sp=r', 'logs/azureml/dataprep/rslex.log': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.df55eae4-d8b8-4943-8ee4-9718a7444070/logs/azureml/dataprep/rslex.log?sv=2019-07-07&sr=b&sig=0NBYDFPSdDdI1qx43PF4E%2Bm%2F3gEYHIo2ejdaO7l20vw%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A07%3A06Z&se=2022-04-14T04%3A17%3A06Z&sp=r', 'logs/azureml/dataprep/rslex.log.2022-04-13-20': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.df55eae4-d8b8-4943-8ee4-9718a7444070/logs/azureml/dataprep/rslex.log.2022-04-13-20?sv=2019-07-07&sr=b&sig=W%2BRhJU0JMgE123cuwNShx%2BVSTX0uF1UGKVMDX01D9gk%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A07%3A06Z&se=2022-04-14T04%3A17%3A06Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.df55eae4-d8b8-4943-8ee4-9718a7444070/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=31x8DouN0prAfGR9oDFxXa%2BPWX6dz%2BXJySPMmby6z14%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A07%3A06Z&se=2022-04-14T04%3A17%3A06Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.df55eae4-d8b8-4943-8ee4-9718a7444070/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=4dFL3wqQ5kHYoDSAkLu2gLXeA0Ot2cf2hiO%2FuEP1UA0%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A07%3A06Z&se=2022-04-14T04%3A17%3A06Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.df55eae4-d8b8-4943-8ee4-9718a7444070/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=VjHrS2X275DZY293sYn8EpX8z9yasDkcxp3%2BE5ZTMck%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A07%3A06Z&se=2022-04-14T04%3A17%3A06Z&sp=r'}, 'submittedBy': 'hadar benin'}\n\n\n\n\nStepRunId: 50a7eaa6-9e85-4cce-b5ab-af1fdae9b783\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/50a7eaa6-9e85-4cce-b5ab-af1fdae9b783?wsid=/subscriptions/06c3d5bb-46a2-4d92-9508-c018d06f6452/resourcegroups/evolve-team-rg/workspaces/evolve-ml&tid=72a43063-967e-43c8-8121-0823266b2701\n\nStepRun(transform data drift output) Execution Summary\n=======================================================\nStepRun( transform data drift output ) Status: Finished\n{'runId': '50a7eaa6-9e85-4cce-b5ab-af1fdae9b783', 'target': 'cpu-cluster', 'status': 'Completed', 'startTimeUtc': '2022-04-13T20:16:29.031363Z', 'endTimeUtc': '2022-04-13T20:17:07.309745Z', 'services': {}, 'properties': {'ContentSnapshotId': 'ebd02ff7-dc35-43d8-8a7f-1d3d31b4d328', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '2e347405-0cb1-4e7e-b4f1-d4d7ecc466ba', 'azureml.moduleName': 'transform data drift output', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '7ab0f089', 'azureml.pipelinerunid': '4ed29cd0-bc79-4295-873c-2cb4d3bde788', 'azureml.pipeline': '4ed29cd0-bc79-4295-873c-2cb4d3bde788', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'transform-data-drift-output.py', 'command': '', 'useAbsolutePath': False, 'arguments': [], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpu-cluster', 'dataReferences': {}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'data-drift-env', 'version': '1', 'assetId': 'azureml://locations/westeurope/workspaces/899eb723-9471-475e-9ea2-abcad8a41de5/environments/data-drift-env/versions/1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['bigjson', 'azureml-defaults']}], 'name': 'azureml_d9438b93de534f7f3a68847348170eaf'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220208.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.50a7eaa6-9e85-4cce-b5ab-af1fdae9b783/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=ioygCCEbd8dye28%2FhugHYawXZrc1CGPrUppo921G4Ko%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A07%3A12Z&se=2022-04-14T04%3A17%3A12Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.50a7eaa6-9e85-4cce-b5ab-af1fdae9b783/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=U7J6kM80nrW6R8ilSLVBKgzYjHrVzR5sR5kjUA%2BgvOo%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A07%3A12Z&se=2022-04-14T04%3A17%3A12Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.50a7eaa6-9e85-4cce-b5ab-af1fdae9b783/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=bkEAmOlwc8mzAhtFGm%2BOr4cc646ctte2oAt8PtjdC68%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A07%3A12Z&se=2022-04-14T04%3A17%3A12Z&sp=r'}, 'submittedBy': 'hadar benin'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '4ed29cd0-bc79-4295-873c-2cb4d3bde788', 'status': 'Completed', 'startTimeUtc': '2022-04-13T20:12:46.709423Z', 'endTimeUtc': '2022-04-13T20:17:10.887314Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.4ed29cd0-bc79-4295-873c-2cb4d3bde788/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=5zJfCOX9ymY%2FRvrTl%2BQ87Wwrw213YFkBwerN8G9vP50%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A03%3A07Z&se=2022-04-14T04%3A13%3A07Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.4ed29cd0-bc79-4295-873c-2cb4d3bde788/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=mnG28rzGQj4wUmiy0RFjrMoW93G%2FWqENvkSgKGUyapo%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A03%3A07Z&se=2022-04-14T04%3A13%3A07Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://evolveml3040211544.blob.core.windows.net/azureml/ExperimentRun/dcid.4ed29cd0-bc79-4295-873c-2cb4d3bde788/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=mLHvTN%2Bd6ecOvWL4zQ6lkedlgfhsZFgbOw4StCTEjHM%3D&skoid=a6efb8ac-b3a0-40a4-8779-354b593f2dab&sktid=72a43063-967e-43c8-8121-0823266b2701&skt=2022-04-13T15%3A56%3A08Z&ske=2022-04-15T00%3A06%3A08Z&sks=b&skv=2019-07-07&st=2022-04-13T20%3A03%3A07Z&se=2022-04-14T04%3A13%3A07Z&sp=r'}, 'submittedBy': 'hadar benin'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1649881033688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineRun\n",
        "from azureml.core import Experiment\n",
        "\n",
        "# Publish the pipeline from the run\n",
        "submitted_pipeline_run = PipelineRun(experiment=Experiment(experiment, run_id=pipeline_run.id))\n",
        "published_pipeline = submitted_pipeline_run.publish_pipeline(name='data-drift-output-pipeline',\n",
        "    description='collect, transform and save datadrift output into dataset',\n",
        "    version='1.0',\n",
        "    continue_on_step_failure=False)\n",
        "\n",
        "print('Pipeline scheduled.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
        "\n",
        "# Schedules a daily run of a published pipeline\n",
        "daily = ScheduleRecurrence(frequency='Day', interval=1)\n",
        "pipeline_schedule = Schedule.create(ws, name='data_drift_output_schedule',\n",
        "                                        description='update data drift output every day',\n",
        "                                        pipeline_id=published_pipeline.id,\n",
        "                                        experiment_name='schedule_data_drift_output_pipeline',\n",
        "                                        recurrence=daily)\n",
        "\n",
        "print('Pipeline scheduled.')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}